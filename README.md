# SIADS_591_MILESTONE1
Scripts for milestone 1 Project Data Collection, Manip and cleaning

![alt text](https://github.com/limesarelife/SIADS_591_MILESTONE1/blob/main/BANNER-TEST-AC.png)
 
First script Pytrends_ACNH_version2-4.ipynb takes the villagers names from villagers.csv and creates a list(appended Animal Crossing to the name for each item in the list) from the names which using the built in API function pulls the Google Trends Related Queries and fetches the historical searches per villager name. This is utilized via the pytrends library.  Returns a dictionary of the names searched and the "rising" key contains the 'query' (search conducted) and 'value' which is the number of all time searches related to the animal crossing villager name.  It then pulls out the rising and parses with for loop and dictionary to pull back and append queries and values of villagers names where there were searches on Google and append none's where villager had no google searches.

Second script combining_ACP_Polls takes all 2020 and 2021 ACP MONTHLY POLL VOTE RESULTS and reads in each file and only keeps the Villagers and Tally column which represents the villager name and number of votes received for each character based on favs from ACNH player votes.  Groupby is used to sum up the tally votes by villager name and then the two dataframes (2020 and 2021) are stacked to create one df and then the group by is done one last time to get each character and total number of votes (Tally as sum).  

Third script, Villager_connect_pytrends_results-2.ipynb, cleans and pulls the villager name from the resultant first script (Pytrends_ACNH_version2-4.ipynb) csv file named final_villager_list_v2.csv, the villagers.csv. Number one objective was checking that query conducted on Google had the villagers name in the search query.  A lambda expression was used to create a new column where its purpose wasto see if the villagers name was present in the query (Google search) if true the value in the column was updated to True otherwise it was updated to False.  We had to examine some searches even more that just a simple true false lambda expression, for example in the game we needed to fix June update vs June the villager to False for all the Google Searches (query column) since they referenced the game update and not the villager.  A similar approah was conducted for maple verus maple trees and leaves, this was achieved utilizing np.where to update keep value to false when the query referred to maple leaves ,trees or diy recipe.  Similiar issues were addressed for the villagers Peaches and Cherry versus peaches and cherry trees fruits, diy recipes, items etc with np.where again. Minor clean up some names a bit before merging with the villager name on the villagers.csv file was performed.  Once cleaned a filter was applied to only keep where the keepvalue column is True and then a groupby is done to get the total Google searches by villager name resulting in the pytrend_search_count dataframe.  Both are merged into one dataframe and then the ACP Polls are merged and a overall popularity field is created which is the sum of the total Google searches and ACP Poll total votes tally; one final dataframe Final_Villagers_ACNH.csv is created along with visuals. Note: Villagers that are missing are assumed to have a google search value of zero.

Fourth script,fish_eda.ipynb, takes the fish and insects csv files and concats them into one critters_acnh dataframe, some str.replace is used to fix the common names for web scraping/searching. The critters names are then put to a list and a for loop is used to attached the nookipedia base url plus the critter name from the list. Beautfiul soup is used to scrape Nookipedia.com for the scientific name based on the common name.  The results from bs4 are multiple lists of the same length created during the for loop that are zipped together and then put into a dataframe, critters.  From there a .map is applied to the title column to pull out the scientific name at index 0 based on if its a list or list of lists.  During the for loop used to scrape nookipedia, the common name was kept and appended to a list so the critters dataframe still has the common name to match up to the critters_acnh dataframe (the concat of fish.csv and insects.csv from ACNH), this common name is utilized to merge the critters_acnh with the critters df (this is the bs4 results with the scientific name) into one final df, acnh_critters_sci_name.csv.
Note: if no scienfitic name is on Nookipedia based on common name of fish or insect the resultant name is Unknown

Fifth script,scrape_wikipedia_sci_name.ipynb, uses pd.read_html and the scientific name from script four (fish_eda.ipynb)to fetch the conservation status aka IUCN Red list category off the wikipedia table.  If no conservation status was listed on the table the species (whether fish or insect) is assumed to be of least concern.

Notebooks to follow along for analysis in order:
1. Pytrends_ACNH_version2-4.ipynb (using Google Trends via pytrennds library gets search conducted by villager as query and number of searches historically)
   Note: Because anyone anywhere can play ACNH if they purschased the game and a Nintendo Switch the region is global 
2. combining_ACP_Polls.ipynb (will need to create time series by month to show how fav villagers changed over time, using all time top 20 ACP Poll Villagers)
3. Villager_connect_pytrends_results-2.ipynb (villagers connected with pytrends and acp poll, also with some visuals)
4. fish_eda.ipynb (bad notebook name but its fish and insects uses bs4 and nookipedia to fetch the scientific name based on common name on the data files)
5. scrape_wikipedia_sci_name.ipynb (takes the csv from number 4 and uses the sci name , wikipedia and pd.read_html to get the IUCN Red List Category based on if the wikipedia table has a conservation status. This also has some visuals for the critters created) 

